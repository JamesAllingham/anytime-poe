{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "\n",
    "from jax import random\n",
    "from torchvision import transforms\n",
    "import wandb\n",
    "\n",
    "from src.models import make_Hard_OvR_Ens_loss as make_loss\n",
    "from src.models import make_Hard_OvR_Ens_MNIST_plots as make_plots\n",
    "from src.models import make_Cls_Ens_loss as make_pretrain_loss\n",
    "from src.data import get_image_dataset, NumpyLoader\n",
    "from src.utils.training import setup_training, train_loop\n",
    "from experiments.configs.mnist_hard_ovr_classification import get_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'train_hard_ovr_classifier.ipynb'\n",
    "# ^ W&B doesn't know how to handle VS Code notebooks.\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = random.PRNGKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset, val_dataset = get_image_dataset(\n",
    "    dataset_name=config.dataset_name,\n",
    "    val_percent=config.val_percent,\n",
    "    flatten_img=True,\n",
    "    train_augmentations=[\n",
    "        # transforms.RandomCrop(28, padding=2),\n",
    "        # transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=15),\n",
    "        # transforms.RandomHorizontalFlip(),\n",
    "        # transforms.\n",
    "    ]\n",
    ")\n",
    "train_loader = NumpyLoader(train_dataset, config.batch_size)\n",
    "val_loader = NumpyLoader(val_dataset, config.batch_size)\n",
    "test_loader = NumpyLoader(test_dataset, config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_config = config.copy_and_resolve_references()\n",
    "pretrain_config.model_name = 'Cls_Ens'\n",
    "del pretrain_config.Î²_schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_rng, rng = random.split(rng)\n",
    "init_x = train_dataset[0][0]\n",
    "init_y = train_dataset[0][1]\n",
    "\n",
    "model, state = setup_training(pretrain_config, setup_rng, init_x, init_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, pre_train_state = train_loop(\n",
    "    model, state, pretrain_config, rng, make_pretrain_loss, make_pretrain_loss, train_loader, val_loader,\n",
    "    # test_loader,\n",
    "    wandb_kwargs={\n",
    "        'mode': 'offline',\n",
    "        # 'notes': 'Data augmentation',\n",
    "        # 'tags': ['MNIST testing'],\n",
    "    },\n",
    "    # plot_fn=make_plots,\n",
    "    # plot_freq=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_rng, rng = random.split(rng)\n",
    "init_x = train_dataset[0][0]\n",
    "init_y = train_dataset[0][1]\n",
    "\n",
    "model, state = setup_training(config, setup_rng, init_x, init_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state.replace(params=pre_train_state.params)\n",
    "# Also replace BN (model) state?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, state = train_loop(\n",
    "    model, state, config, rng, make_loss, make_loss, train_loader, val_loader,\n",
    "    # test_loader,\n",
    "    wandb_kwargs={\n",
    "        # 'mode': 'offline',\n",
    "        'notes': 'pre-trained',\n",
    "        'tags': ['MNIST testing', 'pre-trained'],\n",
    "    },\n",
    "    # plot_fn=make_plots,\n",
    "    # plot_freq=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5f1c3e72c33e9d599052a4f04c6971142100cc706e19ec52aa01eeb819b5a8e9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('any-poe')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
